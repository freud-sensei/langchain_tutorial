{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Expression Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prompt + model + output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Verse 1)\n",
      "감옥 벽에 갇혀서 \n",
      "나 홀로 남겨진 시간들\n",
      "어둠에 감싸인 내 마음은\n",
      "자유롭게 흘러가지 않아\n",
      "\n",
      "(Pre-Chorus)\n",
      "하지만 나 또한 인간이야\n",
      "잘못을 인정하고 반성해\n",
      "감옥 안에서 내 안부를 묻지만\n",
      "자유롭게 대답할 수 없어\n",
      "\n",
      "(Chorus)\n",
      "감옥 생활에 가둬진 나의 삶\n",
      "이젠 자유로운 날 기다리며\n",
      "감옥 벽을 넘어서 마주할 날을 꿈꾸며\n",
      "내 노래는 자유로운 날 위해\n",
      "\n",
      "(Verse 2)\n",
      "갇혀있는 공간 속에서\n",
      "내 목소리가 울려 퍼져\n",
      "희망의 빛을 불러와\n",
      "감옥을 뛰어넘을 수 있을까\n",
      "\n",
      "(Pre-Chorus)\n",
      "하지만 나 또한 인간이야\n",
      "잘못을 인정하고 반성해\n",
      "감옥 안에서 내 안부를 묻지만\n",
      "자유롭게 대답할 수 없어\n",
      "\n",
      "(Chorus)\n",
      "감옥 생활에 가둬진 나의 삶\n",
      "이젠 자유로운 날 기다리며\n",
      "감옥 벽을 넘어서 마주할 날을 꿈꾸며\n",
      "내 노래는 자유로운 날 위해\n",
      "\n",
      "(Bridge)\n",
      "어둠이 지나가고 빛이 들 때\n",
      "나의 노래는 더욱더 빛날 거야\n",
      "감옥 벽을 넘어서 자유를 노래하며\n",
      "세상에 희망을 전할게\n",
      "\n",
      "(Chorus)\n",
      "감옥 생활에 가둬진 나의 삶\n",
      "이젠 자유로운 날 기다리며\n",
      "감옥 벽을 넘어서 마주할 날을 꿈꾸며\n",
      "내 노래는 자유로운 날 위해\n",
      "\n",
      "(Outro)\n",
      "감옥 생활에 대한 이 노래를 들어줘\n",
      "자유로운 날을 꿈꾸며 함께 힘을 내봐\n",
      "감옥 벽을 넘어서 희망을 찾아가기를\n",
      "나의 노래가 너를 위해 부를게\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"{topic}에 대한 노래를 작곡해줘\")\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "print(chain.invoke({\"topic\": \"감옥 생활\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='만두에 대한 노래를 작곡해줘')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_value = prompt.invoke({\"topic\": \"만두\"})\n",
    "prompt_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='만두에 대한 노래를 작곡해줘')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to ChatModel: BaseMessage 형태로 return\n",
    "prompt_value.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: 만두에 대한 노래를 작곡해줘'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to LLM: string 형태로 return\n",
    "prompt_value.to_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='만두야 만두야\\n맛있는 만두야\\n부드러운 피로 채워진\\n매콤한 만두야\\n\\n고소한 속에 풍부한 재료\\n한 입 베어보면 행복이 터져\\n김치와 함께라면\\n더욱 더 맛있는 만두야\\n\\n만두야 만두야\\n사랑하는 만두야\\n언제나 내 곁에 있어줘\\n만두야 내 사랑\\n\\n부드러운 피로 감싸진\\n매콤한 만두야\\n언제나 내 곁에 있어줘\\n만두야 내 사랑\\n\\n만두야 만두야\\n맛있는 만두야\\n언제나 내 곁에 있어줘\\n만두야 내 사랑')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from ChatModel: BaseMessage를 return\n",
    "message = model.invoke(prompt_value)\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nAI:\\n\\n♪ 만두에 대한 노래 ♪\\n\\n만두야 만두야\\n김치도 좋지만\\n나는 너를 더 좋아해\\n모양도 예쁘고\\n맛도 정말 좋아\\n만두야 만두야\\n너는 내 인생의 별이야\\n\\n언제나 내 곁에 있는\\n나의 사랑 만두야\\n언제나 내 맘을 따뜻하게\\n해주는 나의 만두야\\n\\n젓가락으로 잡아서\\n입에 넣으면\\n매운 소스와 함께\\n맛있게 녹아들어\\n만두야 만두야\\n너는 내 인생의 별이야\\n\\n언제나 내 곁에 있는\\n나의 사랑 만두야\\n언제나 내 맘을 따뜻하게\\n해주는 나의 만두야\\n\\n언제나 행복하게\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from LLM: string을 return\n",
    "from langchain_openai.llms import OpenAI\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
    "llm.invoke(prompt_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'만두야 만두야\\n맛있는 만두야\\n부드러운 피로 채워진\\n매콤한 만두야\\n\\n고소한 속에 풍부한 재료\\n한 입 베어보면 행복이 터져\\n김치와 함께라면\\n더욱 더 맛있는 만두야\\n\\n만두야 만두야\\n사랑하는 만두야\\n언제나 내 곁에 있어줘\\n만두야 내 사랑\\n\\n부드러운 피로 감싸진\\n매콤한 만두야\\n언제나 내 곁에 있어줘\\n만두야 내 사랑\\n\\n만두야 만두야\\n맛있는 만두야\\n언제나 내 곁에 있어줘\\n만두야 내 사랑'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# string이나 BaseMessage를 input으로 받음\n",
    "# StrOutputParser는 input을 string으로 변환\n",
    "output_parser.invoke(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entire Pipeline\n",
    "\n",
    "1. user input: `{\"topic\": \"만두\"}`\n",
    "2. `PromptTemplate`을 거쳐 `PromptValue`를 return\n",
    "3. `ChatModel`을 거쳐 `ChatMessage`를 return\n",
    "4. `StrOutputParser`을 거쳐 Python string을 return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='선형대수학에 대한 노래를 작곡해줘')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = {\"topic\": \"선형대수학\"}\n",
    "prompt.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='(Verse 1)\\n선형대수학은 신기한 수학이야\\n벡터와 행렬로 문제를 해결해\\n\\n행렬의 곱셈과 덧셈을 배워\\n선형 연립방정식을 풀 수 있어\\n\\n벡터의 선형독립과 차원을 알아\\n기저를 찾아내는 것도 재미있지\\n\\n(Chorus)\\n선형대수학, 우리 함께 공부해봐\\n행렬과 벡터, 선형변환을 알아가\\n\\n(Verse 2)\\n행렬식과 역행렬을 구할 수 있어\\n역행렬을 이용해 행렬방정식도 쉽게 풀 수 있어\\n\\n고유값과 고유벡터는 중요한 개념이야\\n선형변환을 설명하는 데 도움을 주지\\n\\n(Chorus)\\n선형대수학, 우리 함께 공부해봐\\n행렬과 벡터, 선형변환을 알아가\\n\\n(Bridge)\\n선형대수학은 현실세계를 표현하는데\\n다양한 분야에서 응용될 수 있어\\n\\n데이터 분석과 그래픽 처리에도 쓰여\\n컴퓨터 공학과 물리학에서도 필요해\\n\\n(Chorus)\\n선형대수학, 우리 함께 공부해봐\\n행렬과 벡터, 선형변환을 알아가\\n\\n(Outro)\\n선형대수학의 세계로 떠나볼까\\n벡터와 행렬로 더 멋진 세상을 그려봐')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(prompt | model).invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(Verse 1)\\n선형대수학의 세계로 \\n우리 함께 빠져봐요 \\n벡터와 행렬의 매력에 \\n놀라움에 너무 놀라워 \\n\\n(Chorus)\\n선형대수학 세상은 신비로워 \\n방정식과 행렬, 그 깊은 이야기 \\n선형대수학으로 세상을 바꿔봐요 \\n무한한 가능성이 펼쳐지는 곳 \\n\\n(Verse 2)\\n벡터의 덧셈과 뺄셈으로 \\n공간을 여행하는 느낌 \\n행렬의 곱셈으로 선형변환 \\n우리는 세상을 이해해 \\n\\n(Chorus)\\n선형대수학 세상은 신비로워 \\n방정식과 행렬, 그 깊은 이야기 \\n선형대수학으로 세상을 바꿔봐요 \\n무한한 가능성이 펼쳐지는 곳 \\n\\n(Bridge)\\n고유값과 고유벡터의 세계로 \\n특이값 분해까지 \\n선형대수학의 매력에 \\n우리 함께 빠져봐요 \\n\\n(Chorus)\\n선형대수학 세상은 신비로워 \\n방정식과 행렬, 그 깊은 이야기 \\n선형대수학으로 세상을 바꿔봐요 \\n무한한 가능성이 펼쳐지는 곳 \\n\\n(Outro)\\n선형대수학에 빠져들어 \\n우리 함께 세상을 바꿔봐요 \\n벡터와 행렬의 환상에 \\n더 깊이 빠져들어가요'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(prompt | model | output_parser).invoke(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Search Example\n",
    "\n",
    "* RAG: retrieval-augmented generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Gina's job is working at a diner all day.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\"Tommy used to work on the docks\", \"Gina works the diner all day\"],\n",
    "    embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question, using the context if needed:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# RunnableParallel은 context(retriever)와 question(user input) 2가지 object를 가짐\n",
    "setup_and_retrieval = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ")\n",
    "chain = setup_and_retrieval | prompt | model | output_parser\n",
    "chain.invoke(\"What is Gina's job?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Gina works the diner all day'),\n",
       " Document(page_content='Tommy used to work on the docks')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What is Gina's job?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gina's job is working in a diner."
     ]
    }
   ],
   "source": [
    "# Streaming\n",
    "for chunk in chain.stream(\"What is Gina's job?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Gina's job is working at the diner.\",\n",
       " 'Tommy is a person who used to work on the docks.',\n",
       " 'The name of the song with these lyrics is \"Livin\\' on a Prayer\" by Bon Jovi.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch\n",
    "chain.batch([\"What is Gina's job?\", \"Who is Tommy?\", \"What is the name of the song with these lyrics?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnswer: Gina works at a diner.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM instead of Chat Model\n",
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI()\n",
    "llm_chain = (\n",
    "    setup_and_retrieval | prompt | llm | output_parser\n",
    ")\n",
    "llm_chain.invoke(\"What is Gina's job?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gina works at the diner all day.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# different model provider\n",
    "llm_alt = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "alt_chain = (\n",
    "    setup_and_retrieval | prompt | llm_alt | output_parser\n",
    ")\n",
    "alt_chain.invoke(\"What is Gina's job?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: Gina works at the diner all day.\n",
      "\n",
      "Answer: Gina works as a server in a diner."
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import ConfigurableField\n",
    "\n",
    "configurable_model = llm.configurable_alternatives(\n",
    "    ConfigurableField(id=\"model\"),\n",
    "    default_key=\"openai\",\n",
    "    alternative=llm_alt\n",
    ")\n",
    "\n",
    "configurable_chain = (setup_and_retrieval | prompt | configurable_model | output_parser)\n",
    "\n",
    "print(configurable_chain.invoke(\n",
    "    \"What is Gina's job?\",\n",
    "    config={\"model\": \"openai\"}\n",
    "))\n",
    "stream = configurable_chain.stream(\n",
    "    \"What is Gina's job?\",\n",
    "    config={\"model\": \"alternative\"}\n",
    ")\n",
    "for chunk in stream:\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `stream`: stream back chunks of the response\n",
    "* `invoke`: call the chain on an input\n",
    "* `batch`: call the chain on a list of inputs\n",
    "\n",
    "component별 input & output types\n",
    "* `prompt`: `dictionary` -> `PromptValue`\n",
    "* `ChatModel`: single string, list of chat messages or a `PromptValue` -> `ChatMessage`\n",
    "* `LLM`: single string, list of chat messages or a `PromptValue` -> `String`\n",
    "* `OutputParser`: output of `ChatModel` or `LLM` -> depends on the parser\n",
    "* `Retriever`: single string -> list of documents\n",
    "* `Tool`: single string or dictionary -> depends on the tool\n",
    "\n",
    "모든 runnable은 input/output schema가 존재\n",
    "* `input_schema`: input Pydantic model auto-generated from the structure of the runnable\n",
    "* `output_schema`: output Pydantic model auto-generated from the structure of the runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_template(\"Make a short story about {topic}\")\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PromptInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PromptInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'ChatOpenAIInput',\n",
       " 'anyOf': [{'type': 'string'},\n",
       "  {'$ref': '#/definitions/StringPromptValue'},\n",
       "  {'$ref': '#/definitions/ChatPromptValueConcrete'},\n",
       "  {'type': 'array',\n",
       "   'items': {'anyOf': [{'$ref': '#/definitions/AIMessage'},\n",
       "     {'$ref': '#/definitions/HumanMessage'},\n",
       "     {'$ref': '#/definitions/ChatMessage'},\n",
       "     {'$ref': '#/definitions/SystemMessage'},\n",
       "     {'$ref': '#/definitions/FunctionMessage'},\n",
       "     {'$ref': '#/definitions/ToolMessage'}]}}],\n",
       " 'definitions': {'StringPromptValue': {'title': 'StringPromptValue',\n",
       "   'description': 'String prompt value.',\n",
       "   'type': 'object',\n",
       "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'StringPromptValue',\n",
       "     'enum': ['StringPromptValue'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['text']},\n",
       "  'AIMessage': {'title': 'AIMessage',\n",
       "   'description': 'A Message from an AI.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ai',\n",
       "     'enum': ['ai'],\n",
       "     'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'HumanMessage': {'title': 'HumanMessage',\n",
       "   'description': 'A Message from a human.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'human',\n",
       "     'enum': ['human'],\n",
       "     'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'ChatMessage': {'title': 'ChatMessage',\n",
       "   'description': 'A Message that can be assigned an arbitrary speaker (i.e. role).',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'chat',\n",
       "     'enum': ['chat'],\n",
       "     'type': 'string'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role']},\n",
       "  'SystemMessage': {'title': 'SystemMessage',\n",
       "   'description': 'A Message for priming AI behavior, usually passed in as the first of a sequence\\nof input messages.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'system',\n",
       "     'enum': ['system'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['content']},\n",
       "  'FunctionMessage': {'title': 'FunctionMessage',\n",
       "   'description': 'A Message for passing the result of executing a function back to a model.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'function',\n",
       "     'enum': ['function'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'}},\n",
       "   'required': ['content', 'name']},\n",
       "  'ToolMessage': {'title': 'ToolMessage',\n",
       "   'description': 'A Message for passing the result of executing a tool back to a model.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'tool',\n",
       "     'enum': ['tool'],\n",
       "     'type': 'string'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'}},\n",
       "   'required': ['content', 'tool_call_id']},\n",
       "  'ChatPromptValueConcrete': {'title': 'ChatPromptValueConcrete',\n",
       "   'description': 'Chat prompt value which explicitly lists out the message types it accepts.\\nFor use in external schemas.',\n",
       "   'type': 'object',\n",
       "   'properties': {'messages': {'title': 'Messages',\n",
       "     'type': 'array',\n",
       "     'items': {'anyOf': [{'$ref': '#/definitions/AIMessage'},\n",
       "       {'$ref': '#/definitions/HumanMessage'},\n",
       "       {'$ref': '#/definitions/ChatMessage'},\n",
       "       {'$ref': '#/definitions/SystemMessage'},\n",
       "       {'$ref': '#/definitions/FunctionMessage'},\n",
       "       {'$ref': '#/definitions/ToolMessage'}]}},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ChatPromptValueConcrete',\n",
       "     'enum': ['ChatPromptValueConcrete'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['messages']}}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'ChatOpenAIOutput',\n",
       " 'anyOf': [{'$ref': '#/definitions/AIMessage'},\n",
       "  {'$ref': '#/definitions/HumanMessage'},\n",
       "  {'$ref': '#/definitions/ChatMessage'},\n",
       "  {'$ref': '#/definitions/SystemMessage'},\n",
       "  {'$ref': '#/definitions/FunctionMessage'},\n",
       "  {'$ref': '#/definitions/ToolMessage'}],\n",
       " 'definitions': {'AIMessage': {'title': 'AIMessage',\n",
       "   'description': 'A Message from an AI.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ai',\n",
       "     'enum': ['ai'],\n",
       "     'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'HumanMessage': {'title': 'HumanMessage',\n",
       "   'description': 'A Message from a human.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'human',\n",
       "     'enum': ['human'],\n",
       "     'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'ChatMessage': {'title': 'ChatMessage',\n",
       "   'description': 'A Message that can be assigned an arbitrary speaker (i.e. role).',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'chat',\n",
       "     'enum': ['chat'],\n",
       "     'type': 'string'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role']},\n",
       "  'SystemMessage': {'title': 'SystemMessage',\n",
       "   'description': 'A Message for priming AI behavior, usually passed in as the first of a sequence\\nof input messages.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'system',\n",
       "     'enum': ['system'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['content']},\n",
       "  'FunctionMessage': {'title': 'FunctionMessage',\n",
       "   'description': 'A Message for passing the result of executing a function back to a model.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'function',\n",
       "     'enum': ['function'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'}},\n",
       "   'required': ['content', 'name']},\n",
       "  'ToolMessage': {'title': 'ToolMessage',\n",
       "   'description': 'A Message for passing the result of executing a tool back to a model.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'tool',\n",
       "     'enum': ['tool'],\n",
       "     'type': 'string'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'}},\n",
       "   'required': ['content', 'tool_call_id']}}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.output_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
